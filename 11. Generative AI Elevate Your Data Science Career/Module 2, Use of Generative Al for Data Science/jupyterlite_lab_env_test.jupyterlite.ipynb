{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\">\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-on Lab: Considerations for Data Professionals using GenAI\n",
    "\n",
    "**Estimated time needed:** 45 minutes \n",
    "\n",
    "## Overview  \n",
    "\n",
    "In this lab, you will assess and reinforce your understanding of key principles related to the ethical deployment of generative AI, specifically focusing on transparency, fairness, responsibility, accountability, and reliability.  \n",
    "\n",
    "You will be presented with scenarios, and you are expected to provide a solution for the question based on the scenario. To help you with the solutions, a hint is provided for each exercise. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives \n",
    "\n",
    "After completing this lab, you will be able to: \n",
    "\n",
    " - Maintain transparency and fairness in your AI system \n",
    "\n",
    " - Ensure accountability in the deployment of AI chatbot \n",
    "\n",
    " - Enhance the reliability of your AI model to ensure accurate product descriptions \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1:  \n",
    "\n",
    "You are developing a generative AI system that creates personalized content recommendations for users. The system seems to consistently recommend content that aligns with certain cultural and demographic biases.  \n",
    "\n",
    "Users from diverse backgrounds are expressing concern about the lack of transparency and fairness in the recommendations.  \n",
    "\n",
    "How do you maintain transparency and fairness in your AI system? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Type your response here</i>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To maintain transparency and fairness in your AI system, you can take the following steps:\n",
    "\n",
    "### 1. **Audit the Training Data:**\n",
    "   - **Identify Biases:** Analyze the training data to identify any inherent biases. Ensure the dataset is diverse and representative of all user demographics.\n",
    "   - **Data Augmentation:** If certain demographics or cultural groups are underrepresented, consider augmenting the dataset to include more diverse content.\n",
    "\n",
    "### 2. **Implement Fairness Metrics:**\n",
    "   - **Define Fairness Criteria:** Establish clear criteria for what constitutes fairness in your system. This could include demographic parity, equal opportunity, or other relevant metrics.\n",
    "   - **Regular Monitoring:** Continuously monitor the system's recommendations using these fairness metrics to ensure they remain unbiased over time.\n",
    "\n",
    "### 3. **Enhance Transparency:**\n",
    "   - **Explainability Tools:** Use tools and techniques like LIME (Local Interpretable Model-agnostic Explanations) or SHAP (SHapley Additive exPlanations) to make the decision-making process of the AI system more interpretable.\n",
    "   - **User Communication:** Clearly communicate to users how recommendations are generated. Provide an option for users to see why a particular piece of content was recommended to them.\n",
    "\n",
    "### 4. **User Feedback Mechanism:**\n",
    "   - **Feedback Loop:** Implement a feedback mechanism where users can report biases or unfair recommendations. Use this feedback to continuously improve the system.\n",
    "   - **Regular Updates:** Regularly update the system based on user feedback and new data to ensure it remains fair and transparent.\n",
    "\n",
    "### 5. **Ethical Guidelines and Governance:**\n",
    "   - **Ethical Framework:** Develop and adhere to an ethical framework that guides the development and deployment of the AI system.\n",
    "   - **Governance Board:** Establish a governance board to oversee the ethical implications of the AI system and ensure compliance with fairness and transparency standards.\n",
    "\n",
    "### 6. **Bias Mitigation Techniques:**\n",
    "   - **Algorithmic Adjustments:** Use techniques like re-weighting, re-sampling, or adversarial debiasing to mitigate biases in the model.\n",
    "   - **Diverse Development Team:** Ensure the team developing the AI system is diverse, as this can help in identifying and mitigating biases that might not be apparent to a more homogeneous group.\n",
    "\n",
    "### 7. **Regular Audits and Reports:**\n",
    "   - **Third-Party Audits:** Conduct regular third-party audits to assess the fairness and transparency of the AI system.\n",
    "   - **Transparency Reports:** Publish transparency reports that detail the findings of these audits and the steps taken to address any issues.\n",
    "\n",
    "By implementing these steps, you can maintain transparency and fairness in your AI system, ensuring that it provides equitable and understandable recommendations to all users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for hint</summary>\n",
    "Consider steps like conducting a bias assessment, enhancing diversity in training data, implementing explainability features, and establishing a user feedback loop to ensure fairness and transparency in your AI system. \n",
    "</details>\n",
    "\n",
    "<details><summary>Click here for sample solution</summary>\n",
    "To address this issue, you could implement the following steps: \n",
    "\n",
    "1. Conduct a thorough bias assessment to identify and understand the biases present in the training data and algorithms. \n",
    "2. Use specialized tools or metrics to measure and quantify biases in content recommendations. \n",
    "3. Enhance the diversity of your training data by including a broader range of cultural, demographic, and user behavior data. \n",
    "4. Ensure that the training data reflects the diversity of your user base to reduce biases. \n",
    "5. Implement explainability features to provide users with insights into why specific recommendations are made. \n",
    "6. Offer transparency by showing the key factors and attributes influencing the recommendations. \n",
    "7. Establish a user feedback loop where users can report biased recommendations or provide feedback on content relevance. \n",
    "8. Regularly analyze this feedback to iteratively improve the system's fairness. \n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Additional Information**\n",
    "\n",
    ">Some specialized tools that can be used to measure and quantify biases: \n",
    "\n",
    ">Holistic AI Library: This open-source library offers a range of metrics and mitigation strategies for various AI tasks, including content recommendation. It analyzes data for bias across different dimensions and provides visualizations for clear understanding. \n",
    "\n",
    ">Fairness 360: IBM&#39;s Fairness 360 toolkit provides various tools like Aequitas and What-If Tool to analyze bias in data sets, models, and decision-making processes. It offers metrics like statistical parity, differential odds ratio, and counterfactual fairness. IBM moved AI Fairness 360 to LF AI in July 2020. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2  \n",
    "\n",
    "Your company has deployed a chatbot powered by generative AI to interact with customers. The chatbot occasionally generates responses that are inappropriate or offensive, leading to customer dissatisfaction. As the AI developer, how do you take responsibility for these incidents and ensure accountability in the deployment of the AI chatbot? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Type your response here</i>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuring accountability in the deployment of an AI chatbot involves taking responsibility for its actions and implementing measures to prevent and address inappropriate or offensive responses. Here’s how you can approach this:\n",
    "\n",
    "### 1. **Acknowledge and Take Responsibility:**\n",
    "   - **Public Acknowledgment:** Publicly acknowledge the incidents and take responsibility for the chatbot's behavior. Apologize to affected customers and assure them that steps are being taken to address the issue.\n",
    "   - **Internal Review:** Conduct an internal review to understand the root causes of the inappropriate responses.\n",
    "\n",
    "### 2. **Implement Robust Monitoring and Logging:**\n",
    "   - **Real-Time Monitoring:** Set up real-time monitoring to detect inappropriate or offensive responses as they occur.\n",
    "   - **Logging and Auditing:** Maintain detailed logs of all interactions to facilitate auditing and analysis of incidents.\n",
    "\n",
    "### 3. **Enhance the Training Data:**\n",
    "   - **Data Cleaning:** Review and clean the training data to remove any offensive or inappropriate content.\n",
    "   - **Diverse Data Sources:** Ensure the training data includes diverse and representative examples to reduce the likelihood of biased or offensive outputs.\n",
    "\n",
    "### 4. **Implement Content Filters and Moderation:**\n",
    "   - **Pre-Processing Filters:** Use pre-processing filters to detect and block potentially offensive or inappropriate inputs before they reach the chatbot.\n",
    "   - **Post-Processing Filters:** Implement post-processing filters to review and moderate the chatbot's responses before they are sent to users.\n",
    "\n",
    "### 5. **Regular Model Updates and Retraining:**\n",
    "   - **Continuous Improvement:** Regularly update and retrain the model with new data to improve its performance and reduce the occurrence of inappropriate responses.\n",
    "   - **Bias Mitigation:** Use techniques to identify and mitigate biases in the model that could lead to offensive outputs.\n",
    "\n",
    "### 6. **User Feedback Mechanism:**\n",
    "   - **Feedback Channels:** Provide users with easy-to-use channels to report inappropriate or offensive responses.\n",
    "   - **Responsive Action:** Act promptly on user feedback to address issues and improve the chatbot's behavior.\n",
    "\n",
    "### 7. **Transparency and Communication:**\n",
    "   - **Transparency Reports:** Publish transparency reports detailing the steps taken to address incidents and improve the chatbot.\n",
    "   - **User Communication:** Keep users informed about the measures being taken to ensure the chatbot's reliability and appropriateness.\n",
    "\n",
    "### 8. **Ethical Guidelines and Governance:**\n",
    "   - **Ethical Framework:** Develop and adhere to an ethical framework that guides the development and deployment of the chatbot.\n",
    "   - **Governance Board:** Establish a governance board to oversee the ethical implications of the chatbot and ensure accountability.\n",
    "\n",
    "### 9. **Incident Response Plan:**\n",
    "   - **Response Protocol:** Develop a clear incident response protocol to quickly address and mitigate the impact of inappropriate responses.\n",
    "   - **Crisis Management:** Have a crisis management plan in place to handle severe incidents effectively.\n",
    "\n",
    "### 10. **Third-Party Audits:**\n",
    "   - **Independent Audits:** Conduct regular third-party audits to assess the chatbot's performance and adherence to ethical standards.\n",
    "   - **Continuous Improvement:** Use audit findings to continuously improve the chatbot's behavior and accountability measures.\n",
    "\n",
    "By taking these steps, you can ensure accountability in the deployment of your AI chatbot, taking responsibility for its actions and continuously working to improve its performance and reliability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for hint</summary>\n",
    "To address responsibility and accountability, analyze errors, respond swiftly, continuously monitor for inappropriate responses, and communicate openly with stakeholders about corrective actions taken to improve the chatbot&#39;s behavior. \n",
    "</details>\n",
    "\n",
    "<details><summary>Click here for sample solution</summary>\n",
    "Addressing responsibility and accountability in this scenario involves the following steps: \n",
    "\n",
    "1. Conduct a detailed analysis of the inappropriate responses to identify patterns and root causes. \n",
    "2. Determine whether the issues stem from biased training data, algorithmic limitations, or other factors. \n",
    "3. Implement a mechanism to quickly identify and rectify inappropriate responses by updating the chatbot&#39;s training data or fine-tuning the model. \n",
    "4. Communicate openly with affected customers, acknowledge the issue, and assure them of prompt corrective actions. \n",
    "5. Set up continuous monitoring systems to detect and flag inappropriate responses in real-time. \n",
    "6. Implement alerts or human-in-the-loop mechanisms to intervene when the system generates potentially harmful content. \n",
    "7. Clearly communicate the steps taken to address the issue to both internal stakeholders and customers. \n",
    "8. Emphasize the commitment to continuous improvement and the responsible use of AI technology. \n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: \n",
    "\n",
    "Your company has developed a generative AI model that autonomously generates product descriptions for an e-commerce platform. However, users have reported instances where the generated descriptions contain inaccurate information, leading to customer confusion and dissatisfaction. How do you enhance the reliability of your AI model to ensure accurate product descriptions? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Type your response here</i>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enhancing the reliability of your AI model to ensure accurate product descriptions involves several steps to improve the model's performance, accuracy, and trustworthiness. Here’s a comprehensive approach:\n",
    "\n",
    "### 1. **Data Quality and Preprocessing:**\n",
    "   - **High-Quality Data:** Ensure the training data consists of high-quality, accurate, and well-curated product descriptions.\n",
    "   - **Data Cleaning:** Perform thorough data cleaning to remove any inaccuracies, inconsistencies, or irrelevant information from the training dataset.\n",
    "   - **Data Augmentation:** Augment the dataset with diverse and representative examples to cover a wide range of product categories and variations.\n",
    "\n",
    "### 2. **Model Training and Validation:**\n",
    "   - **Robust Training:** Train the model using advanced techniques and algorithms that prioritize accuracy and reliability.\n",
    "   - **Cross-Validation:** Use cross-validation techniques to ensure the model generalizes well to unseen data and reduces overfitting.\n",
    "   - **Regular Updates:** Continuously update and retrain the model with new data to keep it current and accurate.\n",
    "\n",
    "### 3. **Implement Quality Control Mechanisms:**\n",
    "   - **Pre-Processing Checks:** Implement pre-processing checks to validate the input data before it is used to generate descriptions.\n",
    "   - **Post-Processing Reviews:** Use post-processing reviews to verify the accuracy of the generated descriptions before they are published.\n",
    "   - **Automated Quality Metrics:** Develop automated quality metrics to evaluate the accuracy, relevance, and coherence of the generated descriptions.\n",
    "\n",
    "### 4. **Human-in-the-Loop (HITL):**\n",
    "   - **Human Review:** Incorporate a human-in-the-loop system where human reviewers manually check and approve the generated descriptions before they go live.\n",
    "   - **Feedback Loop:** Establish a feedback loop where human reviewers provide feedback to the model to improve its performance over time.\n",
    "\n",
    "### 5. **Error Detection and Correction:**\n",
    "   - **Error Monitoring:** Set up real-time monitoring to detect and flag inaccurate or problematic descriptions as they are generated.\n",
    "   - **Correction Mechanism:** Implement a mechanism to quickly correct or remove inaccurate descriptions and notify relevant stakeholders.\n",
    "\n",
    "### 6. **User Feedback Mechanism:**\n",
    "   - **Feedback Channels:** Provide users with easy-to-use channels to report inaccuracies or issues with product descriptions.\n",
    "   - **Responsive Action:** Act promptly on user feedback to address inaccuracies and improve the model’s reliability.\n",
    "\n",
    "### 7. **Transparency and Communication:**\n",
    "   - **Transparency Reports:** Publish transparency reports detailing the steps taken to improve the accuracy and reliability of the AI model.\n",
    "   - **User Communication:** Keep users informed about the measures being taken to ensure the accuracy of product descriptions.\n",
    "\n",
    "### 8. **Ethical Guidelines and Governance:**\n",
    "   - **Ethical Framework:** Develop and adhere to an ethical framework that guides the development and deployment of the AI model.\n",
    "   - **Governance Board:** Establish a governance board to oversee the ethical implications and ensure the model’s reliability and accuracy.\n",
    "\n",
    "### 9. **Regular Audits and Testing:**\n",
    "   - **Third-Party Audits:** Conduct regular third-party audits to assess the model’s performance and adherence to accuracy standards.\n",
    "   - **Continuous Testing:** Perform continuous testing and validation to identify and address any emerging issues.\n",
    "\n",
    "### 10. **Documentation and Best Practices:**\n",
    "   - **Comprehensive Documentation:** Maintain comprehensive documentation of the model’s development, training, and validation processes.\n",
    "   - **Best Practices:** Follow industry best practices for AI model development and deployment to ensure reliability and accuracy.\n",
    "\n",
    "By implementing these steps, you can significantly enhance the reliability of your AI model, ensuring that it generates accurate and trustworthy product descriptions, thereby improving customer satisfaction and trust."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for hint</summary>\n",
    "To improve reliability, focus on quality assurance testing, use domain-specific training data, adopt an iterative model training approach, and integrate user feedback to iteratively correct errors and enhance the accuracy of the AI-generated product descriptions. \n",
    "</details>\n",
    "\n",
    "<details><summary>Click here for sample solution</summary>\n",
    "To improve the reliability of the AI model in generating product descriptions, consider the following actions: \n",
    "\n",
    "1. Implement rigorous quality assurance testing to evaluate the accuracy of the generated product descriptions. \n",
    "2. Create a comprehensive testing data set that covers a wide range of products and scenarios to identify and address inaccuracies. \n",
    "3. Ensure that the AI model is trained on a diverse and extensive data set specific to the e-commerce domain. \n",
    "4. Include product information from reputable sources to enhance the model's understanding of accurate product details. \n",
    "5. Implement an iterative training approach to continuously update and improve the model based on user feedback and evolving product data. \n",
    "6. Regularly retrain the model to adapt to changes in the product catalog and user preferences. \n",
    "7. Encourage users to provide feedback on inaccurate product descriptions. \n",
    "8. Use this feedback to fine-tune the model, correct errors, and improve the overall reliability of the AI-generated content.  \n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations! You have completed the lab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Dr. Pooja](https://www.linkedin.com/in/p-b28802262/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Contributors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Abhishek Gagneja](https://www.linkedin.com/in/abhishek-gagneja-23051987/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--## Change Log--!>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--|Date (YYYY-MM-DD)|Version|Changed By|Change Description|\n",
    "|-|-|-|-|\n",
    "|2023-12-14|0.1|Abhishek Gagneja|Initial Draft created| --!>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copyright © IBM Corporation. All rights reserved.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "prev_pub_hash": "9e54548042cc959abb34bd633a9f51784fd2555c0dc1ae36f4d6f1c95b8c4f14"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
